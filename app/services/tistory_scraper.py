import requests
from bs4 import BeautifulSoup
from config import NAVER_CLIENT_ID, NAVER_CLIENT_SECRET  # âœ… í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°


def fetch_tistory_content(url: str):
    """ íŠ¹ì • Tistory ë¸”ë¡œê·¸ URLì—ì„œ ë³¸ë¬¸ í¬ë¡¤ë§ """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}

    try:
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            return {"error": "í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ", "status_code": response.status_code}

        soup = BeautifulSoup(response.text, "html.parser")

        # Tistory ë¸”ë¡œê·¸ ë³¸ë¬¸ì€ ë‹¤ì–‘í•œ íƒœê·¸ì— ìˆì„ ìˆ˜ ìˆìŒ (ì—¬ëŸ¬ íŒ¨í„´ í™•ì¸)
        content_div = soup.select_one("div.article_view, div.tt_article_useless_p_margin, div#content")

        if content_div:
            return {"url": url, "content": content_div.get_text(strip=True)}
        else:
            return {"error": "ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ", "url": url}

    except Exception as e:
        return {"error": f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}


def fetch_tistory_blog_content(url: str):
    """ í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§ """
    headers = {"User-Agent": "Mozilla/5.0"}

    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        return {"error": "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ", "url": url}

    soup = BeautifulSoup(response.text, "html.parser")

    # ğŸ”¹ í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ìˆëŠ” íƒœê·¸ë“¤
    content_div = soup.select_one("div.article_view")  # ìµœì‹  í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸
    if not content_div:
        content_div = soup.select_one("div.tt_article_useless_p_margin")  # êµ¬ë²„ì „ í‹°ìŠ¤í† ë¦¬

    if content_div:
        return {"url": url, "content": content_div.get_text(strip=True)}

    return {"error": "ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ", "url": url}




def search_tistory_blogs_api(query: str, max_results: int = 10):
    """ ë„¤ì´ë²„ APIë¥¼ ì‚¬ìš©í•˜ì—¬ í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ê²€ìƒ‰ """

    url = f"https://openapi.naver.com/v1/search/blog.json?query={query}+site:tistory.com&display={max_results}"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }

    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        data = response.json()
        return [{"title": item["title"], "link": item["link"]} for item in data["items"]]
    else:
        return {"error": "ë„¤ì´ë²„ API í˜¸ì¶œ ì‹¤íŒ¨", "status_code": response.status_code}


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

def search_tistory_blogs_selenium(query: str, max_results: int = 10):
    """ í‹°ìŠ¤í† ë¦¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ Seleniumìœ¼ë¡œ í¬ë¡¤ë§ """

    # ğŸ”¹ Chrome ë¸Œë¼ìš°ì € ì‹¤í–‰
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
    search_url = f"https://search.daum.net/search?w=blog&q={query}&site=tistory.com"

    driver.get(search_url)
    driver.implicitly_wait(5)

    results = []
    posts = driver.find_elements(By.CSS_SELECTOR, "a.f_link_b")

    for post in posts[:max_results]:
        title = post.text
        link = post.get_attribute("href")
        results.append({"title": title, "link": link})

    driver.quit()

    # ğŸ”¹ í¬ë¡¤ë§ëœ ê²°ê³¼ í™•ì¸ (ë””ë²„ê¹…)
    print(f"í¬ë¡¤ë§ëœ í‹°ìŠ¤í† ë¦¬ ê²€ìƒ‰ ê²°ê³¼: {results}")

    return results
