import requests
import urllib.parse  # URL ì¸ì½”ë”©ì„ ìœ„í•œ ëª¨ë“ˆ
from config import NAVER_CLIENT_ID, NAVER_CLIENT_SECRET  # âœ… í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°


def search_naver_blogs_api(query: str, max_results: int = 10):
    """ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ API ì‚¬ìš© (Selenium ì—†ì´ í¬ë¡¤ë§) """

    encoded_query = urllib.parse.quote(query)  # ğŸ”¹ URL ì¸ì½”ë”© ì¶”ê°€
    url = f"https://openapi.naver.com/v1/search/blog.json?query={encoded_query}&display={max_results}"

    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET
    }

    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        data = response.json()
        if "items" in data:  # ğŸ”¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            return [{"title": item["title"], "link": item["link"]} for item in data["items"]]
    else:
        print(f"ë„¤ì´ë²„ API ì˜¤ë¥˜: {response.status_code}, {response.text}")  # ğŸ”¹ ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
        return {"error": "ë„¤ì´ë²„ API í˜¸ì¶œ ì‹¤íŒ¨", "status_code": response.status_code}

    return {"error": "ë„¤ì´ë²„ APIì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"}



from bs4 import BeautifulSoup


def get_naver_blog_original_url(blog_url: str):
    """ ë„¤ì´ë²„ ë¸”ë¡œê·¸ì˜ ì›ë³¸ URLì„ ê°€ì ¸ì˜¤ê¸° (iframe ì²˜ë¦¬) """
    headers = {"User-Agent": "Mozilla/5.0"}

    response = requests.get(blog_url, headers=headers)
    if response.status_code != 200:
        return blog_url  # ì‹¤íŒ¨í•˜ë©´ ê¸°ì¡´ URL ë°˜í™˜

    soup = BeautifulSoup(response.text, "html.parser")

    # ğŸ”¹ iframe ë‚´ë¶€ì˜ ì›ë³¸ ë§í¬ ê°€ì ¸ì˜¤ê¸°
    iframe = soup.select_one("iframe#mainFrame")
    if iframe:
        original_url = "https://blog.naver.com" + iframe["src"]
        return original_url

    return blog_url  # iframeì´ ì—†ìœ¼ë©´ ì›ë˜ URL ë°˜í™˜


def fetch_naver_blog_content(url: str):
    """ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§ (iframe í•´ê²°) """
    headers = {"User-Agent": "Mozilla/5.0"}

    # ğŸ”¹ ì›ë³¸ URL ê°€ì ¸ì˜¤ê¸°
    real_url = get_naver_blog_original_url(url)

    response = requests.get(real_url, headers=headers)
    if response.status_code != 200:
        return {"error": "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ", "url": url}

    soup = BeautifulSoup(response.text, "html.parser")

    # ğŸ”¹ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ìˆëŠ” íƒœê·¸ë“¤ (ìµœì‹  & êµ¬ë²„ì „)
    content_div = soup.select_one("div.se-main-container")  # ìµœì‹  ë„¤ì´ë²„ ë¸”ë¡œê·¸
    if not content_div:
        content_div = soup.select_one("div#postViewArea")  # êµ¬ë²„ì „ ë„¤ì´ë²„ ë¸”ë¡œê·¸

    if content_div:
        return {"url": url, "content": content_div.get_text(strip=True)}

    return {"error": "ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ", "url": url}
