import re
from sklearn.feature_extraction.text import TfidfVectorizer



#  TF-IDFë€?
# TF (Term Frequency): ë¬¸ì„œì—ì„œ íŠ¹ì • ë‹¨ì–´ê°€ ì–¼ë§ˆë‚˜ ìì£¼ ë“±ì¥í•˜ëŠ”ì§€
# IDF (Inverse Document Frequency): ê·¸ ë‹¨ì–´ê°€ ì–¼ë§ˆë‚˜ í¬ê·€í•œì§€
# ì¦‰, "ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ë°©ë²•"
def extract_keywords(text: str, top_n: int = 5):
    """ ë¸”ë¡œê·¸ ë³¸ë¬¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (TF-IDF ì‚¬ìš©) """
    #  íŠ¹ìˆ˜ë¬¸ì ì œê±° & ì†Œë¬¸ì ë³€í™˜
    text = re.sub(r"[^ê°€-í£a-zA-Z0-9\s]", "", text.lower())

    #  TF-IDF ë²¡í„°í™”
    vectorizer = TfidfVectorizer(stop_words=["ìˆë‹¤", "í•˜ë‹¤", "ë˜ë‹¤"])  # ë¶ˆìš©ì–´ ì œê±° ê°€ëŠ¥
    tfidf_matrix = vectorizer.fit_transform([text])

    #  ì¤‘ìš” í‚¤ì›Œë“œ ìƒìœ„ nê°œ ì¶”ì¶œ
    keywords = sorted(
        zip(vectorizer.get_feature_names_out(), tfidf_matrix.toarray()[0]),
        key=lambda x: x[1], reverse=True
    )[:top_n]

    return [word for word, score in keywords]



# ê°ì„± ë¶„ì„ì´ë€?
# ë¸”ë¡œê·¸ ê¸€ì´ ê¸ì •ì ì¸ì§€, ë¶€ì •ì ì¸ì§€ ë¶„ì„í•˜ëŠ” ë°©ë²•
# "ì´ ì„œë¹„ìŠ¤ ë„ˆë¬´ ì¢‹ì•„ìš”!" â†’ ê¸ì • ğŸ˜ƒ
# "ì´ê±° ìµœì•…ì´ì•¼..." â†’ ë¶€ì • ğŸ˜¡
# "ê·¸ëƒ¥ ì“¸ë§Œí•´ìš”" â†’ ì¤‘ë¦½ ğŸ˜

import pandas as pd
from konlpy.tag import Okt

# ê°ì„± ì‚¬ì „ ë°ì´í„° ë¡œë“œ
SENTIMENT_DICT_PATH = "data/KnuSentiLex.csv"

def load_sentiment_dict():
    """ ê°ì„± ì‚¬ì „ ë¡œë“œ (KNU í•œêµ­ì–´ ê°ì„± ì‚¬ì „) """
    df = pd.read_csv(SENTIMENT_DICT_PATH)
    sentiment_dict = dict(zip(df['word'], df['polarity']))
    return sentiment_dict

sentiment_dict = load_sentiment_dict()  # ì‚¬ì „ ë¡œë“œ
okt = Okt()

def analyze_sentiment(text: str):
    """ í•œê¸€ ê°ì„± ë¶„ì„ (ì‚¬ì „ ê¸°ë°˜) """
    words = okt.morphs(text)  # í˜•íƒœì†Œ ë¶„ì„ (ë‹¨ì–´ ë‹¨ìœ„ ì¶”ì¶œ)
    sentiment_score = sum(sentiment_dict.get(word, 0) for word in words)

    if sentiment_score > 0:
        return "ê¸ì • ğŸ˜€"
    elif sentiment_score < 0:
        return "ë¶€ì • ğŸ˜¡"
    else:
        return "ì¤‘ë¦½ ğŸ˜"



# beomi/KcELECTRA-base ëª¨ë¸ ë¡œë“œ & ê°ì„± ë¶„ì„ ì½”ë“œ
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch

# ê°ì„± ë¶„ì„ ì „ìš© beomi/KcELECTRA-base ëª¨ë¸ ì‚¬ìš© (ì¼ë°˜ beomi/KcELECTRA-base ì‚¬ìš©í•˜ë©´ ì˜¤ë¥˜ ë°œìƒ)
MODEL_NAME = "beomi/KcELECTRA-base"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

def analyze_sentiment_kcbert(text: str):
    """ beomi/KcELECTRA-base ì´ìš©í•œ í•œê¸€ ê°ì„± ë¶„ì„ (ì˜¬ë°”ë¥¸ ê°ì„± ë¶„ì„ ëª¨ë¸ ì‚¬ìš©) """
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)

    with torch.no_grad():  # ëª¨ë¸ ì¶”ë¡  ëª¨ë“œ
        outputs = model(**inputs)

    score = torch.softmax(outputs.logits, dim=1)[0]

    # ëª¨ë¸ì´ ì œê³µí•˜ëŠ” ë ˆì´ë¸”ì´ ê¸ì •/ë¶€ì •ì¸ì§€ í™•ì¸ í•„ìš”
    if score[1] > score[0]:  # ê¸ì • í™•ë¥ ì´ ë†’ìœ¼ë©´ ê¸ì •
        return "ê¸ì • ğŸ˜€"
    else:  # ë¶€ì • í™•ë¥ ì´ ë†’ìœ¼ë©´ ë¶€ì •
        return "ë¶€ì • ğŸ˜¡"
