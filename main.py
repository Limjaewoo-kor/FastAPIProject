from services.html_scraper import fetch_blog_content
from services.rss_scraper import fetch_rss_feed
from services.text_analyzer import extract_keywords, analyze_sentiment, analyze_sentiment_kcbert
from services.google_scraper import search_tistory_google
import matplotlib.font_manager as fm
import io
import base64
from fastapi import FastAPI, Request
from fastapi.templating import Jinja2Templates
import matplotlib.pyplot as plt
from models import SessionLocal, init_db
from services.naver_scraper import search_naver_blogs_api, fetch_naver_blog_content
from services.tistory_scraper import search_tistory_blogs_api, fetch_tistory_blog_content
from services.text_analyzer import extract_keywords, analyze_sentiment_kcbert
from fastapi import Depends
from sqlalchemy.orm import Session
from models import BlogPost
from fastapi.middleware.cors import CORSMiddleware



app = FastAPI()
#  Jinja2 í…œí”Œë¦¿ ì„¤ì •
templates = Jinja2Templates(directory="templates")
# ğŸ”¹ ì•± ì‹œì‘ ì‹œ DB ì´ˆê¸°í™”
init_db()

# ğŸ”¹ DB ì„¸ì…˜ ìƒì„±
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


app.add_middleware(
    CORSMiddleware,
    # allow_origins=["http://localhost:3000"],  # React ê°œë°œ ì„œë²„ ì£¼ì†Œ
    allow_origins=["*"],  # React ê°œë°œ ì„œë²„ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

#  ì‹œìŠ¤í…œ ë‚´ í•œê¸€ í°íŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
font_list = [f.name for f in fm.fontManager.ttflist]
print(font_list)  # ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ì¶œë ¥

#  í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rc('font', family='Malgun Gothic')  # Windows: ë§‘ì€ ê³ ë”•
# plt.rc('font', family='AppleGothic')  # Mac: ì• í”Œê³ ë”•
# plt.rc('font', family='NanumGothic')  # Linux: ë‚˜ëˆ”ê³ ë”•

plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

@app.get("/")
def home(request: Request):
    """ ë©”ì¸ í˜ì´ì§€ (ê²€ìƒ‰ ì…ë ¥ í™”ë©´) """
    return templates.TemplateResponse("main.html", {"request": request})


@app.get("/dashboard2/")
def show_dashboard2(request: Request, query: str, max_results: int = 5, top_n: int = 5, db: Session = Depends(get_db)):
    """ í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ê²€ìƒ‰ â†’ ë³¸ë¬¸ í¬ë¡¤ë§ â†’ ë¶„ì„ ê²°ê³¼ë¥¼ ëŒ€ì‹œë³´ë“œë¡œ ì‹œê°í™” """
    # search_results = search_tistory_blogs_api(query, max_results)
    search_results = search_tistory_google(query, max_results)

    analyzed_results = []
    for result in search_results:
        analysis = fetch_tistory_blog_content(result["link"])
        if "error" in analysis:
            continue  # ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨í•œ ê²½ìš° ì œì™¸

        keywords = extract_keywords(analysis["content"], top_n)
        sentiment = analyze_sentiment_kcbert(analysis["content"])

        # ğŸ”¹ ê²°ê³¼ë¥¼ DBì— ì €ì¥
        db_post = BlogPost(
            source="í‹°ìŠ¤í† ë¦¬",
            query=query,
            title=result["title"],
            url=result["link"],
            keywords=",".join(keywords),
            sentiment=sentiment
        )
        db.add(db_post)
        db.commit()

        analyzed_results.append({
            "title": result["title"],
            "url": result["link"],
            "keywords": keywords,
            "sentiment": sentiment
        })

    # í‚¤ì›Œë“œ ë¶„ì„ ì°¨íŠ¸ ìƒì„±
    keyword_freq = {}
    for result in analyzed_results:
        for kw in result["keywords"]:
            keyword_freq[kw] = keyword_freq.get(kw, 0) + 1

    # Matplotlib ì°¨íŠ¸ ìƒì„±
    fig, ax = plt.subplots()
    words = list(keyword_freq.keys())
    scores = list(keyword_freq.values())
    ax.barh(words, scores, color='skyblue')
    plt.xlabel("ë“±ì¥ íšŸìˆ˜")
    plt.ylabel("í‚¤ì›Œë“œ")
    plt.title("í‹°ìŠ¤í† ë¦¬ í‚¤ì›Œë“œ ë¶„ì„")

    # ì°¨íŠ¸ë¥¼ Base64ë¡œ ë³€í™˜í•˜ì—¬ HTMLì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ë³€í™˜
    buf = io.BytesIO()
    plt.savefig(buf, format="png")
    buf.seek(0)
    chart_data = base64.b64encode(buf.getvalue()).decode("utf-8")
    plt.close()

    return templates.TemplateResponse("dashboard2.html", {
        "request": request,
        "query": query,
        "results": analyzed_results,
        "chart_data": chart_data
    })


@app.get("/dashboard1/")
def show_dashboard1(request: Request, query: str, max_results: int = 5, top_n: int = 5, db: Session = Depends(get_db)):
    """ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ â†’ ë³¸ë¬¸ í¬ë¡¤ë§ â†’ ë¶„ì„ ê²°ê³¼ë¥¼ ëŒ€ì‹œë³´ë“œë¡œ ì‹œê°í™” """
    search_results = search_naver_blogs_api(query, max_results)

    analyzed_results = []
    for result in search_results:
        analysis = fetch_naver_blog_content(result["link"])
        if "error" in analysis:
            continue  # ì˜¤ë¥˜ ë°œìƒ ì‹œ í•´ë‹¹ ê¸€ ì œì™¸

        keywords = extract_keywords(analysis["content"], top_n)
        sentiment = analyze_sentiment_kcbert(analysis["content"])

        # ğŸ”¹ ê²°ê³¼ë¥¼ DBì— ì €ì¥
        db_post = BlogPost(
            source="ë„¤ì´ë²„",
            query=query,
            title=result["title"],
            url=result["link"],
            keywords=",".join(keywords),
            sentiment=sentiment
        )
        db.add(db_post)
        db.commit()

        analyzed_results.append({
            "title": result["title"],
            "url": result["link"],
            "keywords": keywords,
            "sentiment": sentiment
        })

    # í‚¤ì›Œë“œ ë¶„ì„ ì°¨íŠ¸ ìƒì„±
    keyword_freq = {}
    for result in analyzed_results:
        for kw in result["keywords"]:
            keyword_freq[kw] = keyword_freq.get(kw, 0) + 1

    # Matplotlib ì°¨íŠ¸ ìƒì„±
    fig, ax = plt.subplots()
    words = list(keyword_freq.keys())
    scores = list(keyword_freq.values())
    ax.barh(words, scores, color='skyblue')
    plt.xlabel("ë“±ì¥ íšŸìˆ˜")
    plt.ylabel("í‚¤ì›Œë“œ")
    plt.title("ë„¤ì´ë²„ í‚¤ì›Œë“œ ë¶„ì„")

    # ì°¨íŠ¸ë¥¼ Base64ë¡œ ë³€í™˜í•˜ì—¬ HTMLì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ë³€í™˜
    buf = io.BytesIO()
    plt.savefig(buf, format="png")
    buf.seek(0)
    chart_data = base64.b64encode(buf.getvalue()).decode("utf-8")
    plt.close()

    return templates.TemplateResponse("dashboard1.html", {
        "request": request,
        "query": query,
        "results": analyzed_results,
        "chart_data": chart_data
    })



#RSS í¬ë¡¤ë§ API
@app.get("/rss/")
def get_rss_feed(url: str, limit: int = 5):
    """ RSS í”¼ë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” API """
    # http://127.0.0.1:8000/rss/?url=https://techcrunch.com/feed/&limit=3
    data = fetch_rss_feed(url, limit)
    return {"status": "success", "data": data}


#í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ í¬ë¡¤ë§ API
@app.get("/blog-content/")
def get_blog_content(url: str):
    """ íŠ¹ì • ë¸”ë¡œê·¸ URLì—ì„œ ì œëª©ê³¼ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” API """
    # http://127.0.0.1:8000/blog-content/?url=https://lcoding.tistory.com/199
    data = fetch_blog_content(url)
    return {"status": "success", "data": data}


#  í‚¤ì›Œë“œ ë¶„ì„ API (TF-IDF)
@app.get("/analyze-keywords/")
def get_keywords(url: str, top_n: int = 5):
    # http://127.0.0.1:8000/analyze-keywords/?url=https://lcoding.tistory.com/199&top_n=5
    data = fetch_blog_content(url)  # ë¸”ë¡œê·¸ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°
    if "error" in data:
        return data

    keywords = extract_keywords(data["content"], top_n)
    return {"status": "success", "keywords": keywords}


# ê°ì„± ë¶„ì„ API [ê°ì„± ë‹¨ì–´ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°]
@app.get("/analyze-sentiment/")
def get_sentiment(url: str):
    # http://127.0.0.1:8000/analyze-sentiment/?url=https://lcoding.tistory.com/199
    data = fetch_blog_content(url)  # ë¸”ë¡œê·¸ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°
    if "error" in data:
        return data

    sentiment = analyze_sentiment(data["content"])
    return {"status": "success", "sentiment": sentiment}




#  KcBERT ê°ì„± ë¶„ì„ API ì¶”ê°€ [ë¬¸ë§¥ì„ ì´í•´í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸]
@app.get("/analyze-sentiment-kcbert/")
def get_sentiment_kcbert(url: str):
    """ KcBERT ê°ì„± ë¶„ì„ API """
    # http://127.0.0.1:8000/analyze-sentiment/?url=https://lcoding.tistory.com/199
    # https://blogdiary0525.tistory.com/65 ì§œì¦ì˜ˆì‹œurl
    # https://blogfindhappy.tistory.com/1 ê¸ì •ì˜ˆì‹œurl
    data = fetch_blog_content(url)  # ë¸”ë¡œê·¸ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°
    if "error" in data:
        return data

    sentiment = analyze_sentiment_kcbert(data["content"])
    return {"status": "success", "sentiment": sentiment}



@app.get("/search-tistory-google/")
def search_tistory_google_api(query: str):
    """ Google ê²€ìƒ‰ì„ í†µí•´ Tistory ë¸”ë¡œê·¸ ìƒìœ„ 10ê°œ í¬ìŠ¤íŒ… ê²€ìƒ‰ """
    results = search_tistory_google(query)
    return {"status": "success", "data": results}


from services.tistory_scraper import fetch_tistory_content

@app.get("/fetch-tistory-content/")
def fetch_tistory(url: str):
    """ Tistory ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§ API """
    data = fetch_tistory_content(url)
    return {"status": "success", "data": data}


from services.text_analyzer import extract_keywords, analyze_sentiment_kcbert

@app.get("/analyze-tistory/")
def analyze_tistory(url: str, top_n: int = 5):
    """ Tistory ë¸”ë¡œê·¸ ë³¸ë¬¸ì„ í¬ë¡¤ë§í•˜ê³  í‚¤ì›Œë“œ ë¶„ì„ & ê°ì„± ë¶„ì„ ìˆ˜í–‰ """
    data = fetch_tistory_content(url)
    if "error" in data:
        return data

    keywords = extract_keywords(data["content"], top_n)
    sentiment = analyze_sentiment_kcbert(data["content"])

    return {
        "status": "success",
        "url": url,
        "keywords": keywords,
        "sentiment": sentiment
    }


from services.naver_scraper import search_naver_blogs_api,fetch_naver_blog_content
from services.tistory_scraper import search_tistory_blogs_api, fetch_tistory_blog_content, search_tistory_blogs_selenium
from services.text_analyzer import extract_keywords, analyze_sentiment_kcbert


@app.get("/search-analyze-naver/")
def search_analyze_naver(query: str, max_results: int = 5, top_n: int = 5, db: Session = Depends(get_db)):
    #http://127.0.0.1:8000/search-analyze-naver/?query=backend&max_results=5&top_n=5

    """ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ â†’ ë³¸ë¬¸ í¬ë¡¤ë§ â†’ ë¶„ì„ ìë™í™” """
    search_results = search_naver_blogs_api(query, max_results)

    analyzed_results = []
    for result in search_results:
        analysis = fetch_naver_blog_content(result["link"])
        if "error" in analysis:
            continue  # ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨í•œ ê²½ìš° ì œì™¸

        keywords = extract_keywords(analysis["content"], top_n)
        sentiment = analyze_sentiment_kcbert(analysis["content"])

        # ğŸ”¹ ê²°ê³¼ë¥¼ DBì— ì €ì¥
        db_post = BlogPost(
            source="ë„¤ì´ë²„",
            query=query,
            title=result["title"],
            url=result["link"],
            keywords=",".join(keywords),
            sentiment=sentiment
        )
        db.add(db_post)
        db.commit()

        analyzed_results.append({
            "title": result["title"],
            "url": result["link"],
            "keywords": keywords,
            "sentiment": sentiment
        })

    return {"status": "success", "data": analyzed_results}


@app.get("/search-analyze-tistory/")
def search_analyze_tistory(query: str, max_results: int = 5, top_n: int = 5, db: Session = Depends(get_db)):

    # http://127.0.0.1:8000/search-analyze-tistory/?query=backend&max_results=5&top_n=5

    """ í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ê²€ìƒ‰ â†’ ë³¸ë¬¸ í¬ë¡¤ë§ â†’ ë¶„ì„ ìë™í™” """
    # search_results = search_tistory_blogs_api(query, max_results)
    search_results = search_tistory_google(query, max_results)

    analyzed_results = []
    for result in search_results:
        analysis = fetch_tistory_blog_content(result["link"])
        if "error" in analysis:
            continue  # ë³¸ë¬¸ í¬ë¡¤ë§ ì‹¤íŒ¨í•œ ê²½ìš° ì œì™¸

        keywords = extract_keywords(analysis["content"], top_n)
        sentiment = analyze_sentiment_kcbert(analysis["content"])

        # ğŸ”¹ ê²°ê³¼ë¥¼ DBì— ì €ì¥
        db_post = BlogPost(
            source="í‹°ìŠ¤í† ë¦¬",
            query=query,
            title=result["title"],
            url=result["link"],
            keywords=",".join(keywords),
            sentiment=sentiment
        )
        db.add(db_post)
        db.commit()

        analyzed_results.append({
            "title": result["title"],
            "url": result["link"],
            "keywords": keywords,
            "sentiment": sentiment
        })

    return {"status": "success", "data": analyzed_results}

